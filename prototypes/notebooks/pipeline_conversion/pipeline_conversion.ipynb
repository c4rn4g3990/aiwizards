{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "⚠️ Need to have .env file in the project root with OPENAI_API_KEY={your_openai_key}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install langchain openai python-dotenv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: GitHub Actions Pipeline\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    branches:\n",
      "      - main\n",
      "  pull_request:\n",
      "    branches:\n",
      "      - main\n",
      "\n",
      "env:\n",
      "  GCP_PROJECT: test-project\n",
      "  GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_KEY }}\n",
      "  GCP_APP_NAME: my-app\n",
      "\n",
      "jobs:\n",
      "  build:\n",
      "    runs-on: ubuntu-latest\n",
      "\n",
      "    steps:\n",
      "      - name: Checkout\n",
      "        uses: actions/checkout@v2\n",
      "\n",
      "      - name: Set up Node.js\n",
      "        uses: actions/setup-node@v2\n",
      "        with:\n",
      "          node-version: '14'\n",
      "\n",
      "      - name: Install dependencies\n",
      "        run: npm install\n",
      "\n",
      "      - name: Build\n",
      "        run: npm run build\n",
      "\n",
      "      - name: Test\n",
      "        run: npm test\n",
      "\n",
      "      - name: Static Code Analysis\n",
      "        run: npm run eslint\n",
      "\n",
      "      - name: Code Quality\n",
      "        run: npm run sonar-scanner\n",
      "\n",
      "      - name: Integration Test\n",
      "        run: npm run integration-test\n",
      "\n",
      "      - name: Code Coverage\n",
      "        run: npm run code-coverage\n",
      "\n",
      "      - name: Publish Code Coverage Report\n",
      "        uses: actions/upload-artifact@v2\n",
      "        with:\n",
      "          name: Code Coverage\n",
      "          path: coverage\n",
      "\n",
      "      - name: Package Artifacts\n",
      "        run: npm run package\n",
      "        env:\n",
      "          ARTIFACTS_PATH: path/to/package\n",
      "\n",
      "      - name: Archive Artifacts\n",
      "        uses: actions/upload-artifact@v2\n",
      "        with:\n",
      "          name: Artifacts\n",
      "          path: path/to/artifacts\n",
      "\n",
      "      - name: Deploy to GCP\n",
      "        if: github.ref == 'refs/heads/deployment-branch'\n",
      "        run: |\n",
      "          echo \"$GCP_SERVICE_ACCOUNT_KEY\" > gcp-key.json\n",
      "          gcloud auth activate-service-account --key-file=gcp-key.json\n",
      "          gcloud config set project $GCP_PROJECT\n",
      "          gcloud app deploy --version=$GITHUB_RUN_NUMBER --quiet\n",
      "\n",
      "      - name: Notify\n",
      "        uses: dawidd6/action-send-mail@v2\n",
      "        with:\n",
      "          server_address: smtp.gmail.com\n",
      "          server_port: 587\n",
      "          username: ${{ secrets.EMAIL_USERNAME }}\n",
      "          password: ${{ secrets.EMAIL_PASSWORD }}\n",
      "          subject: Pipeline Notification\n",
      "          body: The build is complete. Please check the results.\n",
      "          to: your-email@example.com\n",
      "          attachments: ${{ github.run_id }}.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(temperature = 0, openai_api_key=openai_api_key)\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template_file('data/system_prompt.txt', [])\n",
    "with open('data/jenkins-pipeline.txt', 'r') as file:\n",
    "    contents = file.read()\n",
    "\n",
    "user_prompt = \"\"\"Convert the following Jenkins pipeline to GitHub Actions pipeline:\n",
    "{input}\"\"\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt,\n",
    "     HumanMessagePromptTemplate.from_template(user_prompt)]\n",
    ")\n",
    "\n",
    "conversation = LLMChain(prompt=chat_prompt, llm=chat)\n",
    "\n",
    "response = conversation.predict(input = contents)\n",
    "\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T00:06:46.462987Z",
     "start_time": "2023-07-02T00:06:26.601610Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
